# ğŸ­ Playwright Pytest â€“ E2E e API

Projeto de automaÃ§Ã£o com **testes E2E** (Playwright) e **testes de API** (requests + pytest), alinhado Ã  documentaÃ§Ã£o de casos de teste em `docs/`.

---

## ğŸ“– Como funciona o projeto

Dois tipos de automaÃ§Ã£o em um Ãºnico projeto: testes no navegador (**E2E**) e testes de API (**HTTP**). Tudo roda com **pytest**.

| Tipo | Ferramenta | Pasta | O que testa |
|------|------------|--------|-------------|
| **E2E** | Playwright | `playwright/e2e/` | Interface (ex.: Amazon.com.br â€“ busca de livro) |
| **API** | requests + pytest | `playwright/api/` | REST (ex.: JSONPlaceholder â€“ GET/POST `/posts`) |

- **DocumentaÃ§Ã£o:** casos de teste em `docs/test-cases-e2e.md` e `docs/test-cases-api.md`; o cÃ³digo segue essa documentaÃ§Ã£o.
- **ExecuÃ§Ã£o:** `pytest` roda tudo; use `pytest -m e2e` (sÃ³ E2E) ou `pytest -m api` (sÃ³ API).
- **ConfiguraÃ§Ã£o:** `pytest.ini` define `pythonpath` e os markers `e2e` e `api`.

---

## ğŸ“‹ PrÃ©-requisitos e instalaÃ§Ã£o

- Python 3.11+
- pip
- Acesso Ã  internet (para Amazon.com.br e JSONPlaceholder)

## ğŸš€ InstalaÃ§Ã£o

```bash
git clone <url-do-repositorio>
cd playwright-pytest
pip install -r requirements.txt
playwright install   # sÃ³ para testes E2E
```

---

## ğŸ§ª Executando os testes

```bash
pytest                    # todos
pytest -m e2e            # sÃ³ E2E
pytest -m api             # sÃ³ API (rÃ¡pido, sem browser)
pytest -v                 # verboso
pytest playwright/e2e/ -v
pytest playwright/api/test_api_posts.py -v

python -m pytest playwright/e2e/test_amazon_busca_livro.py -v --headed | *comando alternativo*


```

E2E em modo visual: `pytest playwright/e2e/test_amazon_busca_livro.py -v --headed`

---

## ğŸ“Š RelatÃ³rio Allure

Cada execuÃ§Ã£o do `pytest` grava resultados em `allure-results/` (configurado no `pytest.ini`). O relatÃ³rio em HTML Ã© gerado a partir dessa pasta.

### Ver localmente

1. **Instale o Allure CLI:** `scoop install allure` ou `choco install allure` (Windows), `brew install allure` (Mac), ou [releases](https://github.com/allure-framework/allure2/releases).
2. Depois de rodar `pytest`, abra o relatÃ³rio: **`allure serve allure-results`** (sobe um servidor e abre no navegador).
3. Alternativa: `allure generate allure-results -o allure-report --clean` e depois `allure open allure-report`.

NÃ£o abra o `index.html` com duplo clique (ficarÃ¡ em "Loading..." por restriÃ§Ãµes do navegador). Use sempre `allure serve` ou `allure open`.

### Ver no CI (GitHub Actions)

- **URL pÃºblica (GitHub Pages):** `https://<SEU_USUARIO>.github.io/<NOME_DO_REPOSITORIO>/` - Por exemplo: https://alamedv.github.io/playwright-pytest/  
  Ative em **Settings â†’ Pages â†’ Source: GitHub Actions**. O relatÃ³rio Ã© atualizado a cada push em `main`/`master`.
- **Artefatos:** em **Actions** â†’ execuÃ§Ã£o â†’ **Artifacts** baixe **allure-report** ou **allure-results** (disponÃ­veis 14 dias).

| Se vocÃª temâ€¦ | Como visualizar |
|--------------|-----------------|
| Pasta **allure-results** (local ou descompactada) | `allure serve .` na pasta |
| Pasta **allure-report** (descompactada) | Na pasta: `python -m http.server 8800` e acesse http://localhost:8800. NÃ£o abra `index.html` direto. |

As pastas `allure-results/` e `allure-report/` estÃ£o no `.gitignore`.

---

## ğŸ“š Casos de teste e estrutura

| Documento | DescriÃ§Ã£o | CÃ³digo |
|-----------|-----------|--------|
| [docs/test-cases-e2e.md](docs/test-cases-e2e.md) | E2E Amazon.com.br â€“ busca de livro | `playwright/e2e/test_amazon_busca_livro.py` |
| [docs/test-cases-api.md](docs/test-cases-api.md) | API JSONPlaceholder â€“ GET/POST `/posts` | `playwright/api/test_api_posts.py` |

```
playwright-pytest/
â”œâ”€â”€ docs/           # Casos de teste (E2E e API)
â”œâ”€â”€ playwright/
â”‚   â”œâ”€â”€ e2e/        # Testes no browser (Playwright)
â”‚   â””â”€â”€ api/        # Testes HTTP (requests)
â”œâ”€â”€ prompts/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

---

## ğŸ”§ ConfiguraÃ§Ã£o

**pytest.ini:** `pythonpath`, markers `e2e` e `api`, e `--alluredir=allure-results --clean-alluredir` (para o relatÃ³rio Allure).

**VariÃ¡veis de ambiente (opcional):** URL base ou headless para E2E; base URL da API pode ser externalizada no cÃ³digo.

---

## ğŸ› Debug

```bash
PWDEBUG=1 pytest playwright/e2e/test_amazon_busca_livro.py
pytest playwright/e2e/test_amazon_busca_livro.py --screenshot on --video on
```

---

## ğŸ”„ CI (GitHub Actions)

**Workflow:** `.github/workflows/ci.yml` â€” push/PR em `main` e `master`. Passos: checkout, Python 3.11, dependÃªncias, Playwright, `pytest`, geraÃ§Ã£o do Allure Report, upload de artefatos e deploy no GitHub Pages (em push em `main`/`master`).

Sem secrets necessÃ¡rios para os testes atuais. Para o relatÃ³rio em URL pÃºblica, ative **Settings â†’ Pages â†’ Source: GitHub Actions** (detalhes na seÃ§Ã£o [RelatÃ³rio Allure](#-relatÃ³rio-allure)).

---

## ğŸ“¦ DependÃªncias

- **pytest** â€“ execuÃ§Ã£o dos testes
- **pytest-playwright** â€“ testes E2E no browser
- **playwright** â€“ automaÃ§Ã£o de browser
- **requests** â€“ chamadas HTTP nos testes de API
- **allure-pytest** â€“ geraÃ§Ã£o dos resultados para o relatÃ³rio Allure

Definidas em `requirements.txt`.

---

## ğŸ¤– Respostas do Desafio TÃ©cnico

### QuestÃ£o 4 â€“ InteligÃªncia Artificial

**1. Quais aspectos vocÃª avaliaria ao testar uma aplicaÃ§Ã£o similar ao ChatGPT ([chatgpt.com](https://chatgpt.com/))?**

R: Ao testar uma aplicaÃ§Ã£o baseada em IA, eu avaliaria:

Quando se trata de utilizaÃ§Ã£o de IA eu tenho algumas consideraÃ§Ãµes a serem avaliadas e respeitadas. A principal Ã© se ela estÃ¡ criando a mais do que se Ã© pedido (uma pessoa com 6 dedos ou braÃ§o a mais. Ou codigo duplicado no caso do mundo dev). Outros fatores sÃ£o a performance, desempenho e tambÃ©m a seguranÃ§a.

---

### Uso de IA no Processo de QA

**1. Qual ferramenta ou tÃ©cnica de IA foi utilizada?**  
*(Ex: TestRigor, Mabl, Applitools com IA visual, ChatGPT para geraÃ§Ã£o de testes)*

R: As questÃµes 1 e 2 foram respondidas com auxilio da IA atravÃ©s da IDE chamada CURSOR. Esse programa Ã© derivado do VS code e tem uma inteligencia artificial integrada que auxilia (via chat) inclusive refatorando cÃ³digo ou testando manualmente (sim, vocÃª pode configurar pra IA testar manualmente os cenÃ¡rios antes de automatizar).


**2. Para qual propÃ³sito a IA foi aplicada?**  
*(Ex: geraÃ§Ã£o automÃ¡tica de casos de teste, detecÃ§Ã£o de falhas visuais, automaÃ§Ã£o de scripts)*

R: AlÃ©m dos exemplos citados acima, conforme poderÃ¡ ver no cÃ³digo o script de automaÃ§Ã£o, a IA foi aplicada pra fazer uma exploraÃ§Ã£o e uma anÃ¡lise inteligente do caso de teste e somente depois disso comeÃ§ar a cÃ³digos para testes automatizados. Caso algo dÃª errado no caminho, ela vai procurando alternativas (de acordo com o ranking que foi disponibilizado de correÃ§Ã£o). 

Isso permitiu mais confiabilidade na criaÃ§Ã£o da automatizaÃ§Ã£o dos testes.


**3. Como a IA impactou o processo de QA e os resultados obtidos?**

R: Os pontos principais foram a reduÃ§Ã£o do tempo na criaÃ§Ã£o de cÃ³digo. Aumento da estabilidade dos testes (ao evitar seletores frÃ¡geis). Com isso pude focar em lapidar a arquitetura dos testes de imediato.
